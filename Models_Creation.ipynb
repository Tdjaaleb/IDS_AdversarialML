{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from cleverhans.tf2.attacks import fast_gradient_method as FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/multi_data.csv\")\n",
    "\n",
    "Train, Test = train_test_split(df, test_size=0.33, random_state=69)\n",
    "\n",
    "df_tensor_input_Train=tf.convert_to_tensor(Train.drop(['intrusion','Dos','normal','Probe','R2L','U2R','label'], axis=1))\n",
    "df_tensor_output_Train=tf.convert_to_tensor(Train[['Dos','normal','Probe','R2L','U2R']]) \n",
    "\n",
    "df_tensor_input_Test=tf.convert_to_tensor(Test.drop(['intrusion','Dos','normal','Probe','R2L','U2R','label'], axis=1))\n",
    "df_tensor_output_Test=tf.convert_to_tensor(Test[['Dos','normal','Probe','R2L','U2R']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = tf.keras.Sequential()\n",
    "mlp.add(tf.keras.layers.Dense(units=48, input_dim=df_tensor_input_Train.shape[1], activation=\"relu\"))\n",
    "mlp.add(tf.keras.layers.Dense(units=5, activation=\"softmax\"))\n",
    "mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "mlp.summary()\n",
    "\n",
    "mlp.fit(df_tensor_input_Train, df_tensor_output_Train, epochs=100)\n",
    "\n",
    "pred = mlp.predict(df_tensor_input_Test)\n",
    "\n",
    "for j in range(0,pred.shape[1]):\n",
    "  for i in range(0,pred.shape[0]):\n",
    "    pred[i][j] = int(round(pred[i][j]))\n",
    "\n",
    "pred_df = pd.DataFrame(pred,columns=Train[['Dos','normal','Probe','R2L','U2R']].columns)\n",
    "\n",
    "print(\"Recall Score - \",recall_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8'),average='micro'))\n",
    "print(\"F1 Score - \",f1_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8'),average='micro'))\n",
    "print(\"Precision Score - \",precision_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8'),average='micro'))\n",
    "print(\"Accuracy Score - \", accuracy_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = FGSM.fast_gradient_method(mlp, df_tensor_input_Train, 0.2, np.inf)\n",
    "adv_df = pd.DataFrame(adv.numpy())\n",
    "adv_df.columns = Train.columns.drop(['intrusion','Dos','normal','Probe','R2L','U2R','label'])\n",
    "\n",
    "mlp.fit(adv_df, df_tensor_output_Train, epochs=10)\n",
    "\n",
    "pred = mlp.predict(df_tensor_input_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred,columns=Train[['Dos','normal','Probe','R2L','U2R']].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.max(axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.iloc[[0]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,pred_df.shape[0]):\n",
    "    pred_df.where(pred_df.iloc[[i]]==pred_df.iloc[[i]].max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(0,pred.shape[1]):\n",
    "  for i in range(0,pred.shape[0]):\n",
    "    pred[i][j] = int(round(pred[i][j]))\n",
    "\n",
    "pred_df = pd.DataFrame(pred,columns=Train[['Dos','normal','Probe','R2L','U2R']].columns)\n",
    "\n",
    "print(\"Recall Score - \",recall_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8'),average='micro'))\n",
    "print(\"F1 Score - \",f1_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8'),average='micro'))\n",
    "print(\"Precision Score - \",precision_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8'),average='micro'))\n",
    "print(\"Accuracy Score - \", accuracy_score(Test[['Dos','normal','Probe','R2L','U2R']],pred_df.astype('uint8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_state = []\n",
    "pred_state = []\n",
    "\n",
    "for i in range(0,pred.shape[0]):\n",
    "    lab = [\"Dos\",\"normal\",\"Probe\",\"R2L\",\"U2R\"]\n",
    "    for j in range(0,pred.shape[1]):\n",
    "        if pred[i][j]==1:\n",
    "            true_state.append(Test[\"label\"])\n",
    "            pred_state.append(lab[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0963322607b61fb85e60b3c63581df9ac5d2bad434271279b035d9d92170e8cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
