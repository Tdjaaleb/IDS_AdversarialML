{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.tf2.attacks import fast_gradient_method as FGSM\n",
    "from cleverhans.tf2.attacks import carlini_wagner_l2 as CW\n",
    "from cleverhans.tf2.attacks import basic_iterative_method\n",
    "from cleverhans.tf2.attacks import madry_et_al\n",
    "from cleverhans.tf2.attacks import momentum_iterative_method\n",
    "from cleverhans.tf2.attacks import spsa\n",
    "from cleverhans.tf2.attacks import projected_gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Preprocessed_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor_input=tf.convert_to_tensor(df.drop([\"frame.number\",\"normality\"], axis=1))\n",
    "df_tensor_output=tf.convert_to_tensor(df[\"normality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=df_tensor_input.shape[1]\n",
    "\n",
    "inputs = tf.keras.Input(shape=(input_dim,))\n",
    "x = tf.keras.layers.Dense(units=8, activation=\"sigmoid\")(inputs)\n",
    "outputs = tf.keras.layers.Dense(units=5, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss= 'mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df_tensor_input, df_tensor_output, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(df_tensor_input)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.imdb.load_data()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation(tf.nn.softmax) # We seperate the activation layer to be able to access the logits of the previous layer later\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss= 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(df_tensor_input, df_tensor_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = FGSM.fast_gradient_method(model, df_tensor_input, 0.05, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleverhans\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation(tf.nn.softmax) # We seperate the activation layer to be able to access the logits of the previous layer later\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss= 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_split=0.2)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.tf2.attacks import fast_gradient_method as FGSM\n",
    "\n",
    "#The attack requires the model to ouput the logits\n",
    "logits_model = tf.keras.Model(model.input,model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(test_images.shape[0])\n",
    "\n",
    "original_image = test_images[random_index]\n",
    "original_image = tf.convert_to_tensor(original_image.reshape((1,28,28))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
    "\n",
    "original_label = test_labels[random_index]\n",
    "original_label = np.reshape(original_label, (1,)).astype('int64') # Give label proper shape and type for cleverhans\n",
    "\n",
    "#Show the image\n",
    "plt.figure()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.imshow(np.reshape(original_image, (28,28)))\n",
    "plt.title(\"Label: {}\".format(original_label[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "\n",
    "adv_example_untargeted_label = FGSM.fast_gradient_method(\n",
    "    model_fn=model, \n",
    "    x=original_image, \n",
    "    eps=epsilon, \n",
    "    norm=np.inf, \n",
    "    targeted=False)\n",
    "\n",
    "adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
    "\n",
    "#Show the image\n",
    "plt.figure()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.imshow(np.reshape(adv_example_untargeted_label, (28,28)))\n",
    "plt.title(\"Model Prediction: {}\".format(np.argmax(adv_example_untargeted_label_pred)))\n",
    "plt.xlabel(\"Original Label: {}\".format(original_label[0]))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0963322607b61fb85e60b3c63581df9ac5d2bad434271279b035d9d92170e8cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
